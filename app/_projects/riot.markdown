---
title       : RIOT
type        : residency
season      : Winter 2018

description : An interactive film experience which positions viewers in a riot in progress. The narrative branches based on viewer's emotional facial expressions.

thumb-alt   : A man seen from behind watching a largw screen with riot police depicted on it

image       : /images/projects/riot/og.jpg

artist      : Karen Palmer

team :
  - name : Angelica Perez
    role : Developer & Project Lead
  - name : Stephanie Weber
    role : Developer & Researcher
  - name : Sofia Tania
    role : Developer
  - name : Ella Holmes
    role : Developer

extended-team :
  - name : Aldo Noyola
  - name : Andrew McWilliams
    link : /bio/andrew-mcwilliams/
  - name : Andy Slocum
  - name : Ankit Shukla
    link : https://www.linkedin.com/in/ankit-shukla-562912143/
  - name : Ashni Mehta
    link : http://twitter.com/@ashni_mehta
  - name : Juba Trajano
    link : https://www.linkedin.com/in/trajanoneto
  - name : Ellen Pearlman
    link : /bio/ellen-pearlman/
  - name : Emily Wu
    link : https://www.emilyjwu.com/
  - name : Marina Tassi
  - name : Mason Richins
  - name : Megan Louw
  - name : Miguel Enriquez
    link : https://twitter.com/eldermael
  - name : MR Ngo
  - name : Nathan Zeplowitz
  - name : Puneetha Pai
    link : https://www.linkedin.com/in/puneeth-pai-b3b299a1/
  - name : Ricardo Peters
    link : https://www.linkedin.com/in/petersricardo
  - name : Sanin Adnan
    link : http://blog.saninsoftware.com/
  - name : Sriram Viswanathan
    link : https://www.linkedin.com/in/sriramvish/
  - name : Tim Kadom

---

*RIOT* is an immersive, emotionally responsive, live-action film that positions viewers in the middle of a riot in progress. The film responds to participants’ emotional expressions using artificial intelligence, altering the video story journey in real-time.

{% include image file='riot-1.jpg'
   alt='An audience member standing in front of the installation in a dark room'
   caption='An audience member experiencing the *RIOT* installation' %}

The *RIOT* film installation experience allows viewers to consider how they might react in the face of imminent danger. A webcam or camera is used to monitor each viewer’s facial characteristics as they watch the film, and the video narrative responds accordingly.

For example, if the viewer appears agitated, the character in the film responds defensively or impatiently. The same is true for a number of other assessed emotional expressions, such as calmness or fear.

{% include image file='developers.jpg'
   alt='Engineers discussing the project with Karen in front of a whiteboard'
   caption='Karen working with Thoughtworks developers Sofia Tania and Angelica Perez' %}

*RIOT* provides feedback into complex cultural issues surrounding split second decisions in times of actual crisis. It places viewers at the center of a provocative story for which there are a number of potential live time scenarios which may triggered by their authentic reaction.

## Development of a New Prototype
During her time at the Thoughtworks Arts Residency, Karen worked with Thoughtworks developers on a [new machine learning-based facial expression analysis system](https://github.com/thoughtworksarts/EmoPy), and on enhancing the [storyline management](https://github.com/thoughtworksarts/riot-storyline-manager) and [*RIOT* user experience](https://github.com/thoughtworksarts/riot).

As a result, Karen can add new emotional expressions to the experience, and can add new narrative layers to the *RIOT* prototype via a custom-built user interface.

{% include image file='open-studios.jpg'
   alt='People discussing the work in an office setting'
   caption='Karen at one of her regular \'Open Studios\'' %}

The *RIOT* experience works with a deep neural net toolkit for emotional expression analysis, created by Thoughtworks, named *EmoPy*. The system has [been made open source](https://github.com/thoughtworksarts/EmoPy) in order to provide free access beyond existing closed-box commercial implementations, both widening access and encouraging debate.

As of 2019, EmoPy is [featured as a Thoughtworks project on the Open Source homepage](https://www.thoughtworks.com/open-source).

Karen's previous work with [Dr. Hongying Meng](https://www.brunel.ac.uk/people/hongying-meng) of Brunel University, London, was refined and developed as part of the piece. This includes his research and implementation of new facial expression analysis techniques.

{% include image file='riot-2.jpg'
   alt='A "police officer" keeping guard as visitors try out the RIOT experience'
   caption='*RIOT* exhibited at SPRING/BREAK as part of a Thoughtworks Arts exhibition during Armory Week' %}

During her residency, Karen hosted regular 'Open Studios' events at Thoughtworks New York. Stakeholders from across industry, academia and the arts were invited to discuss the implications of AI technology, using the residency and artwork as a focal point for critical discussion.

Karen undertook research on human emotional understanding with Emily Balcetis, Associate Professor of Psychology at the [Social Perception, Action & Motivation Lab](https://sites.google.com/a/nyu.edu/nyu-spam-lab/home) at New York University. This research continues as Karen moves forward with new versions of the *RIOT* system.

## Exhibitions and publications

In the fall of 2017 Karen [spoke at TED New York](/blog/karen-palmer-film-watches-you-back/), telling the story of her work from conception through to the Thoughtworks Arts Residency. Karen goes on to explain the next stages of development for *RIOT*, which will deal with a greater range of emotions, more narratives and a multiplayer experience.

{% include youtube id='Rw8gLEkFdSw' %}

The *RIOT* film experience was exhibited at the [SPRING/BREAK art fair](https://thoughtworksarts.io/spring-break/) as part of New York's Armory Week, alongside other Thoughtworks Arts-incubated artists. It has been exhibited at the [Future of Storytelling Festival](https://futureofstorytelling.org/project/riot), the Museum of Modern Art Peru, and Festival of the Mind Sheffield.

The project has also been featured in global publications including [Forbes](https://www.forbes.com/sites/katmustatea/2017/12/30/this-filmmaker-from-the-future-can-teach-you-to-channel-your-fear/), [CBS](http://newyork.cbslocal.com/2017/06/16/impulse-response/), [The Guardian](https://www.theguardian.com/science/blog/2017/mar/29/its-a-riot-the-stressful-ai-simulation-built-to-understand-your-emotions), [Fast Company](https://www.fastcompany.com/40498786/when-your-fear-is-the-remote-control), [NBC](http://www.nbcnews.com/tech/security/facial-recognition-technology-raises-privacy-concerns-n676836), [WIRED](https://www.wired.co.uk/article/karen-palmer-racist-bias), [Engadget](https://www.engadget.com/2017/10/13/riot-2-interactive-film-karen-palmer-interview/) and the [New York Times](https://www.nytimes.com/2016/10/02/nyregion/storytelling-in-the-virtual-age-at-fost-fest.html).